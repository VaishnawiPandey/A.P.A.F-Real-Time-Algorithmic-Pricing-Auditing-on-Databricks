{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d3a8129-0b1b-42ff-8a06-4857950a328e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required paths and variables defined for Silver Layer processing.\n✅ Step 5: Product Catalog created: ecommerce_audit.audit_schema.product_catalog_static\n✅ Step 6: Silver Stream finished. Enriched data in: ecommerce_audit.audit_schema.silver_enriched_events\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from pyspark.sql.functions import col, unix_timestamp, current_timestamp\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "# --- CRITICAL FIX: DEFINE UC_ROOT AGAIN ---\n",
    "# Replace with your actual Volume details\n",
    "UC_ROOT = \"/Volumes/ecommerce_audit/audit_schema/audit_volume/APAF_Capstone_Project\"\n",
    "\n",
    "# --- Define ALL Unity Catalog Paths (for tables/schemas) ---\n",
    "bronze_table_name = \"ecommerce_audit.audit_schema.bronze_price_requests\"\n",
    "silver_product_table_name = \"ecommerce_audit.audit_schema.product_catalog_static\"\n",
    "silver_enriched_table_name = \"ecommerce_audit.audit_schema.silver_enriched_events\"\n",
    "\n",
    "# --- Define Checkpoint Path (Must be unique for the Silver Stream) ---\n",
    "# We still need the UC_ROOT for the checkpoint folder location\n",
    "dbfs_checkpoint_silver = f\"{UC_ROOT}/_checkpoints/silver/{str(uuid.uuid4())}\" \n",
    "\n",
    "print(\"All required paths and variables defined for Silver Layer processing.\")\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# --- Define Paths (Unity Catalog Names) ---\n",
    "silver_product_table_name = \"ecommerce_audit.audit_schema.product_catalog_static\"\n",
    "\n",
    "# --- Create Mock Data for 20 Products (Product ID, Category, Base Cost) ---\n",
    "products_data = [\n",
    "    (\"PROD_0001\", \"Electronics\", 1500), (\"PROD_0002\", \"Electronics\", 80),\n",
    "    (\"PROD_0003\", \"Apparel\", 25), (\"PROD_0004\", \"Apparel\", 300),\n",
    "    (\"PROD_0005\", \"HomeGoods\", 120), (\"PROD_0006\", \"HomeGoods\", 45),\n",
    "    (\"PROD_0007\", \"Beauty\", 65), (\"PROD_0008\", \"Beauty\", 20),\n",
    "    (\"PROD_0009\", \"Tools\", 750), (\"PROD_0010\", \"Tools\", 30),\n",
    "    (\"PROD_0011\", \"Books\", 15), (\"PROD_0012\", \"Books\", 50),\n",
    "    (\"PROD_0013\", \"Toys\", 40), (\"PROD_0014\", \"Toys\", 10),\n",
    "    (\"PROD_0015\", \"Sports\", 90), (\"PROD_0016\", \"Sports\", 180),\n",
    "    (\"PROD_0017\", \"Auto\", 400), (\"PROD_0018\", \"Auto\", 200),\n",
    "    (\"PROD_0019\", \"Kitchen\", 150), (\"PROD_0020\", \"Kitchen\", 250)\n",
    "]\n",
    "\n",
    "product_schema = StructType([\n",
    "    StructField(\"product_id\", StringType(), False),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"base_cost\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "product_df = spark.createDataFrame(products_data, product_schema)\n",
    "\n",
    "# --- Write to Unity Catalog Table (Static Silver) ---\n",
    "product_df.write \\\n",
    "  .format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .saveAsTable(silver_product_table_name) \n",
    "\n",
    "print(f\"✅ Step 5: Product Catalog created: {silver_product_table_name}\")\n",
    "\n",
    "####Step--6 Silver Stream Transformation (Stream-Static Join)\n",
    "\n",
    "from pyspark.sql.functions import col, unix_timestamp, current_timestamp\n",
    "from pyspark.sql.types import TimestampType\n",
    "import uuid\n",
    "\n",
    "# --- Paths ---\n",
    "bronze_table_name = \"ecommerce_audit.audit_schema.bronze_price_requests\"\n",
    "silver_product_table_name = \"ecommerce_audit.audit_schema.product_catalog_static\"\n",
    "silver_enriched_table_name = \"ecommerce_audit.audit_schema.silver_enriched_events\"\n",
    "# Checkpoint location must be a new, unique path for Silver stream\n",
    "dbfs_checkpoint_silver = f\"{UC_ROOT}/_checkpoints/silver/{str(uuid.uuid4())}\" \n",
    "\n",
    "# --- 1. Define Streaming Read (from Bronze Delta) ---\n",
    "bronze_stream_df = spark.readStream.table(bronze_table_name)\n",
    "\n",
    "# --- 2. Load Static Product Catalog ---\n",
    "product_df_static = spark.read.table(silver_product_table_name) \n",
    "\n",
    "# --- 3. Transformation and Join (PySpark) ---\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "silver_df = (\n",
    "    bronze_stream_df\n",
    "    .withColumn(\n",
    "        \"event_time_ts\",\n",
    "        expr(\"try_to_timestamp(event_time, \\\"yyyy-MM-dd'T'HH:mm:ss.SSSSSS'Z'\\\")\")\n",
    "    )\n",
    "    .join(product_df_static, [\"product_id\"], \"inner\")\n",
    "    .withColumn(\"price_markup\", col(\"request_price\") - col(\"base_cost\"))\n",
    "    .select(\n",
    "        col(\"request_id\"),\n",
    "        col(\"event_time_ts\").alias(\"event_time\"),\n",
    "        col(\"user_id\"),\n",
    "        col(\"product_id\"),\n",
    "        col(\"category\"),\n",
    "        col(\"geo_cluster\"),\n",
    "        col(\"request_price\"),\n",
    "        col(\"price_markup\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- 4. Write to Silver Delta Table ---\n",
    "silver_query = (\n",
    "    silver_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", dbfs_checkpoint_silver)\n",
    "    .trigger(once=True) # Use the successful Trigger.Once() pattern\n",
    "    .queryName(\"Silver_Enrichment_Stream\")\n",
    "    .toTable(silver_enriched_table_name)\n",
    ")\n",
    "\n",
    "silver_query.awaitTermination()\n",
    "\n",
    "print(f\"✅ Step 6: Silver Stream finished. Enriched data in: {silver_enriched_table_name}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}